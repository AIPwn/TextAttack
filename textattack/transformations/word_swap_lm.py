import numpy as np
import os
import torch

from textattack.shared import utils
from textattack.transformations.word_swap import WordSwap
from textattack.tokenizers import BERTTokenizer
from transformers.modeling_bert import BertForMaskedLM

class WordSwapLanguageModel(WordSwap):
    """ 
        Transforms an input by replacing a word with the most likely words generated by a language model.
        Currently, only supports BERT
    """
    
    BERT_PATH = 'models/bert_masked_lm'
    
    def __init__(self, max_candidates=30, language_model="bert",  
        replace_stopwords=False, model=None, tokenizer=None, **kwargs):
        super().__init__(**kwargs)
        self.max_candidates = max_candidates
        self.language_model = language_model
        self.replace_stopwords = replace_stopwords

        if language_model == "bert":
            if tokenizer is None:
                self.tokenizer = BERTTokenizer()
            else:
                self.tokenizer = tokenizer

            if model is None:
                #model_file_path = utils.download_if_needed(BERT_PATH)
                self.model = BertForMaskedLM.from_pretrained('bert-base-uncased')
                self.model.to(utils.get_device())
                self.model.eval()
            else:
                self.model = model

    def __call__(self, tokenized_text, indices_to_replace=None):
        """ 
        Returns a list of possible 'candidate words' to replace a word in a sentence 
            or phrase based off top predictions by a language model
        """
        text = tokenized_text.words
        if not indices_to_replace:
            indices_to_replace = list(range(len(text)))
        
        transformations = []
        tokens_list = []
        segments_list = []
        masked_indices = []
        for i in indices_to_replace:
            if not self.replace_stopwords and text[i].lower() in self.stopwords:
                continue
            masked_indices.append(i)
            masked_text = list(text)
            masked_text[i] = "[MASK]"
            masked_text = " ".join(masked_text)
            tokens_list.append(self.tokenizer.convert_tokens_to_ids(
                self.tokenizer.convert_text_to_tokens(masked_text)))
            segments_list.append([0] * self.tokenizer.max_seq_length)

        if masked_indices:
            transformations = []
            tokens_tensor = torch.tensor(tokens_list, device=utils.get_device())
            segments_tensor = torch.tensor(segments_list, device=utils.get_device())

            with torch.no_grad():
                preds = self.model(tokens_tensor, token_type_ids=segments_tensor)[0]

            for i in range(len(masked_indices)):
                # we do +1 b/c whole text is shifted by 1 when passed to LM
                top_preds = torch.topk(preds[i][masked_indices[i]+1], self.max_candidates)
                top_ids = top_preds.indices
                top_scores = top_preds.values
                top_tokens = self.tokenizer.convert_ids_to_tokens(top_ids)

                for j in range(len(top_tokens)):
                    new_word = recover_word_case(top_tokens[j], text[masked_indices[i]])
                    new_tokenized_text = tokenized_text.replace_word_at_index(masked_indices[i], new_word)
                    new_tokenized_text.attack_attrs["lm_score"] = top_scores[j].item()
                    transformations.append(new_tokenized_text)

            return transformations
        else:
            return []


def recover_word_case(word, reference_word):
    """ Makes the case of `word` like the case of `reference_word`. Supports 
        lowercase, UPPERCASE, and Capitalized. """
    if reference_word.islower():
        return word.lower()
    elif reference_word.isupper() and len(reference_word) > 1:
        return word.upper()
    elif reference_word[0].isupper() and reference_word[1:].islower():
        return word.capitalize()
    else:
        # if other, just do not alter the word's case
        return word